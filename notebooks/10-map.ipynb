{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "# Maps\n",
    "\n",
    "## Agenda\n",
    "\n",
    "1. Discussion: pros/cons of array-backed and linked structures\n",
    "2. `set` and `dict` lookup performance\n",
    "3. The **Map** ADT\n",
    "4. Hashing and Hashcodes\n",
    "5. Hashtables\n",
    "    - Collisions and the \"Birthday problem\"\n",
    "6. Runtime analysis & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## 1. Discussion: pros/cons of array-backed and linked structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "Between the array-backed and linked list we have:\n",
    "\n",
    "1. $O(1)$ indexing (array-backed)\n",
    "2. $O(1)$ appending (array-backed & linked)\n",
    "3. $O(1)$ insertion/deletion without indexing (linked)\n",
    "4. $O(N)$ linear search (unsorted)\n",
    "5. $O(\\log N)$ binary search, when sorted (only array-backed lists)\n",
    "\n",
    "Lists inherently prioritize position-based access due to their sequential nature -- array-backed lists are optimized for direct indexing, while linked lists are excellent for cursor-driven operations.\n",
    "\n",
    "But what if we would like to prioritize search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## 2. `set` and `dict` lookup performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "The `set` and `dict` types don't support positional access (i.e., by index), but do support lookup/search. Just how fast are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# let's use linear and binary search as baselines for comparison\n",
    "\n",
    "def lin_search(lst, x):\n",
    "    for y in lst:\n",
    "        if x == y:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def bin_search(lst, x):\n",
    "    # assumes lst is sorted\n",
    "    low = 0\n",
    "    hi  = len(lst)-1\n",
    "    while low <= hi:\n",
    "        mid = (low + hi) // 2\n",
    "        if x < lst[mid]:\n",
    "            hi  = mid - 1\n",
    "        elif x < lst[mid]:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 6] # set size of plot\n",
    "\n",
    "ns = np.linspace(100, 10_000, 50, dtype=int)\n",
    "\n",
    "to_find = -1\n",
    "\n",
    "ts_linsearch = [timeit.timeit(f'lin_search(lst, lst[{to_find}])',\n",
    "                              setup=f'lst = list(range({n}))',\n",
    "                              globals=globals(),\n",
    "                              number=100)\n",
    "                for n in ns]\n",
    "\n",
    "ts_binsearch = [timeit.timeit(f'bin_search(lst, {to_find})',\n",
    "                              setup=f'lst = list(range({n}))',\n",
    "                              globals=globals(),\n",
    "                              number=100)\n",
    "                for n in ns]\n",
    "\n",
    "ts_setsearch = [timeit.timeit(f'{to_find} in st', \n",
    "                              setup=f'st = set(range({n}))',\n",
    "                              globals=globals(),\n",
    "                              number=100)\n",
    "                for n in ns]\n",
    "\n",
    "ts_dctsearch = [timeit.timeit(f'{to_find} in dct',\n",
    "                              setup=f'dct = {{x:x for x in range({n})}}',\n",
    "                              globals=globals(),\n",
    "                              number=100)\n",
    "                for n in ns]\n",
    "\n",
    "plt.plot(ns, ts_linsearch, 'sr')\n",
    "plt.plot(ns, ts_binsearch, 'sg')\n",
    "plt.plot(ns, ts_setsearch, 'ob')\n",
    "plt.plot(ns, ts_dctsearch, 'om');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "Somehow, by discarding positional access, sets and dictionaries appear to be able to implement search in **constant time**!\n",
    "\n",
    "How is this magic possible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## 3. The **Map** ADT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "We will focus next on the \"*map*\" abstract data type (aka \"associative array\" or \"dictionary\"), which is used to associate keys (which must be unique) with values. \n",
    "\n",
    "A map *does not* intrinsically impose any ordering on its contents --- i.e., an implementation of a map does not need to support positional access to keys, nor report a consistent view of key order.\n",
    "\n",
    "Python's `dict` type is an implementation of the map ADT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "### 3.1. But what about sets?\n",
    "\n",
    "Given an implementation of a map, it should be straightforward to use it to implement a set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySet:\n",
    "    def __init__(self):\n",
    "        self.dct = dict()\n",
    "    \n",
    "    def add(self, value):\n",
    "        pass\n",
    "    \n",
    "    def __contains__(self, value):\n",
    "        pass\n",
    "        \n",
    "    def intersection(self, other):\n",
    "        assert isinstance(other, MySet)\n",
    "        pass\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.dct)\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return '{' + ', '.join(repr(x) for x in self) + '}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = MySet()\n",
    "\n",
    "for c in 'hello world!':\n",
    "    st.add(c)\n",
    "\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set('hello world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st2 = MySet()\n",
    "\n",
    "for c in 'farewell planet':\n",
    "    st2.add(c)\n",
    "    \n",
    "st.intersection(st2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set('hello world!') & set('farewell planet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. A simple map implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "class MapDS:\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "    \n",
    "    def __setitem__(self, key, value):\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        pass\n",
    "            \n",
    "    def __contains__(self, key):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "m = MapDS()\n",
    "m['batman'] = 'bruce wayne'\n",
    "m['superman'] = 'clark kent'\n",
    "m['spiderman'] = 'peter parker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "m['batman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "m['batman'] = 'tony stark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "m['batman']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "How can we make the leap from linear runtime complexity to constant?!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## 4. Hashing and Hashcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "*Hashcodes* (a.k.a. hash values or just hashes) are simple numerical values (typically integers) computed for objects by *hash functions*. Their implementation is typically based on simple mathematical operations, such as multiplication, division, and modular arithmetic, applied to the object's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99162322"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a simple hash function\n",
    "def myhash(s):\n",
    "    h = 0\n",
    "    for c in s:\n",
    "        h = 31 * h + ord(c)\n",
    "    return h\n",
    "\n",
    "myhash('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our purposes, we will consider an object's hashcode to be akin to a \"fingerprint\" of its data. We will also assume that hashcodes are very efficient to compute (i.e., in constant time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python provides a built-in `hash()` function that returns an object's hashcode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "hash('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "hash('batman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "hash('batmen') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "[hash(s) for s in ['different', 'objects', 'have', 'very', 'different', 'hashes']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we use hash codes to help us implement a mapping sttrucre with constant-time lookup?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `hash` function in Python is *randomized* by default -- i.e., each time a Python interpreter is fired up, the implementation of `hash` will use a different \"seed\" for the random number generator used in computing hashes. While hashcodes computed for a given value will be consistent for a given interpreter instance, they will not be across instances! This means we shouldn't save hashcodes for values to disk, or save them to a database, as values will almost certainly hash to different hashcodes after we restart our software!\n",
    "\n",
    "Why does Python do this? More later!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## 5. Hashtables\n",
    "\n",
    "A **hashtable** is an implementation of the map ADT that uses the hashcode for a key to compute an index into an array where the corresponding key/value pair will be stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/10-ht-simple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/10-ht-simple-contains.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "class Hashtable:\n",
    "    def __init__(self, n_buckets):\n",
    "        self.buckets = [None] * n_buckets\n",
    "        \n",
    "    def __setitem__(self, key, val):\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        pass\n",
    "        \n",
    "    def __contains__(self, key):\n",
    "        try:\n",
    "            _ = self[key]\n",
    "            return True\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht = Hashtable(100)\n",
    "ht['spiderman'] = 'peter parker'\n",
    "ht['batman'] = 'bruce wayne'\n",
    "ht['superman'] = 'clark kent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht['spiderman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht['batman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht['superman']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "### 5.1. On Collisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "#### The \"Birthday Problem\"\n",
    "\n",
    "Problem statement: Given $N$ people at a party, how likely is it that at least two people will have the same birthday (assuming a fixed 365 days/year)?\n",
    "\n",
    "How many people do you think are needed for a 50% chance of a shared birthday? 99%?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick to answering the birthday problem is to consider the *complement* of it; i.e., the event of \"no shared birthdays\". The probability that at least two people share a birthday is $1$ minus the probability that *nobody shares a birthday*.\n",
    "\n",
    "- For 1 person, the probability is $1 - 1 = 0$\n",
    "- For 2 people, the probability is $1 - \\frac{364}{365} = \\frac{1}{365}$\n",
    "- For 3 people, the probability is $1 - \\frac{364}{365} \\times \\frac{363}{365}$\n",
    "- For 4 people, the probability is $1 - \\frac{364}{365} \\times \\frac{363}{365} \\times \\frac{362}{365}$\n",
    "- For $N$ people, the probability is $1 - \\frac{364}{365} \\times \\frac{363}{365} \\times \\ldots \\times \\frac{365 - N + 1}{365}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "def birthday_p(n_people):\n",
    "    p_inv = 1\n",
    "    for n in range(365, 365-n_people, -1):\n",
    "        p_inv *= n / 365\n",
    "    return 1 - p_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "birthday_p(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "1-364/365*363/365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "n_people = range(1, 80)\n",
    "plt.plot(n_people, [birthday_p(n) for n in n_people]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "#### General collision statistics\n",
    "Repeat the birthday problem, but with a given number of values and \"buckets\" that are allotted to hold them. How likely is it that two or more values will map to the same bucket?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "def collision_p(n_values, n_buckets):\n",
    "    p_inv = 1\n",
    "    for n in range(n_buckets, n_buckets-n_values, -1):\n",
    "        p_inv *= n / n_buckets\n",
    "    return 1 - p_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "collision_p(23, 365) # same as birthday problem, for 23 people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "collision_p(10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "collision_p(100, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "# keeping number of values fixed at 100, but vary number of buckets: visualize probability of collision\n",
    "n_buckets = range(100, 100001, 1000)\n",
    "plt.plot(n_buckets, [collision_p(100, nb) for nb in n_buckets]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "def avg_num_collisions(n, b):\n",
    "    \"\"\"Returns the expected number of collisions for n values uniformly distributed\n",
    "    over a hashtable of b buckets. Based on (fairly) elementary probability theory.\n",
    "    (Pay attention in MATH 474!)\"\"\"\n",
    "    return n - b + b * (1 - 1/b)**n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "avg_num_collisions(28, 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "avg_num_collisions(1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "avg_num_collisions(1000, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "### 5.2. Dealing with Collisions\n",
    "To deal with collisions in a hashtable, we simply create a \"chain\" of key/value pairs for each bucket where collisions occur. The chain needs to be a data structure that supports quick insertion — natural choice: the linked list!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/10-ht-collisions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/10-ht-contains.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "class Hashtable:\n",
    "    class Node:\n",
    "        def __init__(self, key, val, next=None):\n",
    "            self.key = key\n",
    "            self.val = val\n",
    "            self.next = next\n",
    "            \n",
    "    def __init__(self, n_buckets=1000):\n",
    "        self.buckets = [None] * n_buckets\n",
    "        \n",
    "    def __setitem__(self, key, val):\n",
    "        bidx = hash(key) % len(self.buckets)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        bidx = hash(key) % len(self.buckets)\n",
    "    \n",
    "    def __contains__(self, key):\n",
    "        try:\n",
    "            _ = self[key]\n",
    "            return True\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht = Hashtable(100)\n",
    "ht['batman'] = 'bruce wayne'\n",
    "ht['superman'] = 'clark kent'\n",
    "ht['spiderman'] = 'peter parker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht['batman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht['superman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht['spiderman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "def init_ht(size):\n",
    "    ht = Hashtable(size)\n",
    "    for x in range(size):\n",
    "        ht[x] = x\n",
    "    return ht\n",
    "\n",
    "ns = np.linspace(100, 10_000, 50, dtype=int)\n",
    "ts_htsearch = [timeit.timeit(f'{0} in ht',\n",
    "                             setup='ht = init_ht({})'.format(n),\n",
    "                             globals=globals(),\n",
    "                             number=100)\n",
    "               for n in ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "plt.plot(ns, ts_binsearch, 'ro')\n",
    "plt.plot(ns, ts_htsearch, 'gs')\n",
    "plt.plot(ns, ts_dctsearch, 'b^');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "### 5.3. Loose ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "#### Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "class Hashtable(Hashtable):\n",
    "    def __iter__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht = Hashtable(100)\n",
    "ht['batman'] = 'bruce wayne'\n",
    "ht['superman'] = 'clark kent'\n",
    "ht['spiderman'] = 'peter parker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "for k in ht:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "#### Key ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "ht = Hashtable()\n",
    "d = {}\n",
    "for x in 'apple banana cat dog elephant'.split():\n",
    "    d[x[0]] = x\n",
    "    ht[x[0]] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "for k in d:\n",
    "    print(k, '=>', d[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "for k in ht:\n",
    "    print(k, '=>', ht[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement an ordered hashtable, it is necessary to maintain a separate data structure to keep track of the order of keys (by insertion). Here's a clever way to do it -- you'll flesh it out in lab!\n",
    "\n",
    "![](../images/10-ht-ordered.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal",
    "tags": []
   },
   "source": [
    "### 5.5. Load factor & Rehashing\n",
    "\n",
    "It is clear that the ratio of the number of keys to the number of buckets (known as the **load factor**) can have a significant effect on the performance of a hashtable.\n",
    "\n",
    "A fixed number of buckets doesn't make sense, as it might be wasteful for a small number of keys, and also scale poorly to a relatively large number of keys. And it also doesn't make sense to have the user of the hashtable manually specify the number of buckets (which is a low-level implementation detail). \n",
    "\n",
    "Instead: a practical hashtable implementation would start with a relatively small number of buckets, and if/when the load factor increases beyond some threshold (typically 1), it *dynamically increases the number of buckets* (typically to twice the previous number). This requires that all existing keys be *rehashed* to new buckets (why?).\n",
    "\n",
    "What is the runtime complexity of rehashing a hashtable of *N* keys?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "### 5.6. Uniform hashing\n",
    "\n",
    "Ultimately, the performance of a hashtable also heavily depends on hashcodes being *uniformly distributed* --- i.e., where, statistically, each bucket has roughly the same number of keys hashing to it. Designing hash functions that do this is an algorithmic problem that's outside the scope of this class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## 6. Runtime analysis & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "For a hashtable with $N$ key/value entries, in the worst imaginable scenario all keys hash to the same bucket, and we end up having to navigate through a chain of $N$ collisions when inserting/searching/deleting, which gives us the  following *worst-case runtime complexities*:\n",
    "\n",
    "- Insertion: $O(N)$\n",
    "- Lookup: $O(N)$\n",
    "- Deletion: $O(N)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "BUT, if we assume uniform hashing and the rehashing behavior described above, it is possible to prove that hashtables have $O(1)$ *amortized (i.e., average) runtime complexity*. Proving this is also beyond the scope of this class (but is borne out by empirical data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denial of Service Attacks and Random Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashtables are unique in that they depend on good average case runtime complexity, and the incredibly low likelihood of a large number of collisions happening.\n",
    "\n",
    "But what if someone knew what different values hashed to in advance, and intentionally caused a huge number of keys to be entered into a hashtable that would result in collisions?\n",
    "\n",
    "This is the basis of a **denial of service attack** aimed at taking advantage of the worst-case runtime complexity of a Hashtable! The good news: Python makes this much more difficult by randomizing hashes by default -- but it also means you need to take care to guard your hash function if you implement one yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## Vocabulary list\n",
    "\n",
    "- hashtable\n",
    "- hashing and hashes\n",
    "- collision\n",
    "- hash buckets & chains\n",
    "- birthday problem\n",
    "- load factor\n",
    "- rehashing\n",
    "- denial of service attack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "## Addendum: On *Hashability*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "Remember: *a given object must always hash to the same value*. This is required so that we can always map the object to the same hash bucket.\n",
    "\n",
    "Hashcodes for collections of objects are usually computed from the hashcodes of its contents, e.g., the hash of a tuple is a function of the hashes of the objects in said tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "hash(('two', 'strings'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "This is useful. It allows us to use a tuple, for instance, as a key for a hashtable.\n",
    "\n",
    "However, if the collection of objects is *mutable* — i.e., we can alter its contents — this means that we can potentially change its hashcode.`\n",
    "\n",
    "If we were to use such a collection as a key in a hashtable, and alter the collection after it's been assigned to a particular bucket, this leads to a serious problem: the collection may now be in the wrong bucket (as it was assigned to a bucket based on its original hashcode)!\n",
    "\n",
    "For this reason, only immutable types are, by default, hashable in Python. So while we can use integers, strings, and tuples as keys in dictionaries, lists (which are mutable) cannot be used. Indeed, Python marks built-in mutable types as \"unhashable\", e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "hash([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "That said, Python does support hashing on instances of custom classes (which are mutable). This is because the default hash function implementation does not rely on the contents of instances of custom classes. E.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "class Student:\n",
    "    def __init__(self, fname, lname):\n",
    "        self.fname = fname\n",
    "        self.lname = lname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "s = Student('John', 'Doe')\n",
    "hash(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "s.fname = 'Jane'\n",
    "hash(s) # same as before mutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "We can change the default behavior by providing our own hash function in `__hash__`, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "class Student:\n",
    "    def __init__(self, fname, lname):\n",
    "        self.fname = fname\n",
    "        self.lname = lname\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash(self.fname) + hash(self.lname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "s = Student('John', 'Doe')\n",
    "hash(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "state": "normal"
   },
   "outputs": [],
   "source": [
    "s.fname = 'Jane'\n",
    "hash(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "state": "normal"
   },
   "source": [
    "But be careful: instances of this class are no longer suitable for use as keys in hashtables (or dictionaries), if you intend to mutate them after using them as keys!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "mimir": {
   "data": {},
   "last_submission_id": "",
   "project_id": "aa73d4af-4b00-400e-8c6c-d83178fea3c6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
